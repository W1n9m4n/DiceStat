<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DiceStat Video Detection</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    video { max-width: 100%; }
    #confidenceValue { font-weight: bold; }
  </style>
</head>
<body>
  <h1>DiceStat Video Detection</h1>

  <label for="confidenceSlider">Confidence Threshold: <span id="confidenceValue">0.75</span></label><br />
  <input type="range" id="confidenceSlider" min="0" max="1" step="0.01" value="0.75" />

  <br /><br />
  <video id="video" controls>
    <source src="your_video.mp4" type="video/mp4" />
    Your browser does not support the video tag.
  </video>

  <canvas id="canvas" style="position:absolute; top:0; left:0;"></canvas>

  <script type="module">
    import Roboflow from "https://cdn.jsdelivr.net/npm/@roboflow/inference@1.2.3/dist/roboflow.mjs";

    const rf = new Roboflow({ apiKey: "YOUR_API_KEY_HERE" });
    const model = await rf.load("dice-statistics/3");

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const slider = document.getElementById("confidenceSlider");
    const confidenceValueDisplay = document.getElementById("confidenceValue");

    let confidenceThreshold = parseFloat(slider.value);

    slider.addEventListener("input", () => {
      confidenceThreshold = parseFloat(slider.value);
      confidenceValueDisplay.textContent = confidenceThreshold.toFixed(2);
    });

    // Resize canvas to video size on metadata loaded
    video.addEventListener("loadedmetadata", () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.style.width = video.clientWidth + "px";
      canvas.style.height = video.clientHeight + "px";
      canvas.style.position = "absolute";
      canvas.style.top = video.offsetTop + "px";
      canvas.style.left = video.offsetLeft + "px";
    });

    async function detectFrame() {
      if (video.paused || video.ended) {
        requestAnimationFrame(detectFrame);
        return;
      }

      // Run inference on current video frame
      const predictions = await model.predict(video, { confidence: confidenceThreshold });

      // Clear canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Draw predictions that meet threshold
      predictions.forEach(prediction => {
        if (prediction.confidence >= confidenceThreshold) {
          const { x, y, width, height, class: cls, confidence } = prediction;

          ctx.strokeStyle = "red";
          ctx.lineWidth = 2;
          ctx.font = "18px Arial";
          ctx.fillStyle = "red";

          // Draw bounding box
          ctx.strokeRect(x, y, width, height);
          // Draw label & confidence
          ctx.fillText(`${cls} ${(confidence * 100).toFixed(1)}%`, x, y > 20 ? y - 5 : y + 20);
        }
      });

      requestAnimationFrame(detectFrame);
    }

    video.addEventListener("play", () => {
      detectFrame();
    });
  </script>
</body>
</html>
